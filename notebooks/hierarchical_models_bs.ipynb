{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "from numpyro.infer import SVI, Trace_ELBO, MCMC, NUTS, Predictive\n",
    "import numpyro.distributions as dist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpyro.infer.reparam import NeuTraReparam\n",
    "from numpyro.infer.autoguide import AutoDiagonalNormal\n",
    "from numpyro.handlers import reparam\n",
    "from numpyro.optim import Adam\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import statsmodels.api as sm\n",
    "from numpyro.infer.reparam import LocScaleReparam\n",
    "\n",
    "numpyro.enable_x64()\n",
    "prng_seed = random.PRNGKey(0)\n",
    "assert numpyro.__version__.startswith(\"0.13.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global control variables\n",
    "learning_rate = 1e-2\n",
    "vi_iters = 10000\n",
    "\n",
    "num_warmup = 250\n",
    "num_samples = 1000\n",
    "num_chains = 1\n",
    "thinning = 1\n",
    "target_accept_prob = 0.99\n",
    "max_tree_depth = 12\n",
    "\n",
    "num_resamples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hg_intercept_partial(pool_code, logX_ijt, hyperparameters, logM_ijt=None):\n",
    "    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(10.0))\n",
    "\n",
    "    μ_α = numpyro.sample(\"μ_α\", dist.Normal(hyperparameters['Β_param'][0], np.sqrt(np.diag(hyperparameters['cov_Β'])[0])))\n",
    "    β_1 = numpyro.sample(\"β_1\", dist.Normal(hyperparameters['Β_param'][1], np.sqrt(np.diag(hyperparameters['cov_Β'])[1])))\n",
    "    β_2 = numpyro.sample(\"β_2\", dist.Normal(hyperparameters['Β_param'][2], np.sqrt(np.diag(hyperparameters['cov_Β'])[2])))\n",
    "    β_3 = numpyro.sample(\"β_3\", dist.Normal(hyperparameters['Β_param'][3], np.sqrt(np.diag(hyperparameters['cov_Β'])[3])))\n",
    "    μ_σ = numpyro.sample(\"μ_σ\", dist.HalfNormal(np.sqrt(np.pi/2) * hyperparameters['σ_param']))\n",
    "\n",
    "    n_pairs = len(np.unique(pool_code))\n",
    "    with numpyro.plate(\"levels\", n_pairs):\n",
    "        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n",
    "        σ = numpyro.sample(\"σ\", dist.HalfNormal(np.sqrt(np.pi/2) * μ_σ))\n",
    "\n",
    "    μ_ijt = α[pool_code] + β_1 * logX_ijt[:,0] + β_2 * logX_ijt[:,1] + β_3 * logX_ijt[:,2]\n",
    "    σ_ij = σ[pool_code]\n",
    "\n",
    "    with numpyro.plate(\"data\", len(pool_code)):\n",
    "        numpyro.sample(\"logM_ijt\", dist.TruncatedNormal(μ_ijt, σ_ij, low=0), obs=logM_ijt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hg_fully_partial(pool_code, logX_ijt, hyperparameters, logM_ijt=None):\n",
    "    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(10))\n",
    "    σ_β_1 = numpyro.sample(\"σ_β_1\", dist.HalfNormal(10))\n",
    "    σ_β_2 = numpyro.sample(\"σ_β_2\", dist.HalfNormal(10))\n",
    "\n",
    "    μ_α = numpyro.sample(\"μ_α\", dist.Normal(hyperparameters['Β_param'][0], np.sqrt(np.diag(hyperparameters['cov_Β'])[0])))\n",
    "    μ_β_1 = numpyro.sample(\"μ_β_1\", dist.Normal(hyperparameters['Β_param'][1], np.sqrt(np.diag(hyperparameters['cov_Β'])[1])))\n",
    "    μ_β_2 = numpyro.sample(\"μ_β_2\", dist.Normal(hyperparameters['Β_param'][2], np.sqrt(np.diag(hyperparameters['cov_Β'])[2])))\n",
    "    β_3 = numpyro.sample(\"β_3\", dist.Normal(hyperparameters['Β_param'][3], np.sqrt(np.diag(hyperparameters['cov_Β'])[3])))\n",
    "    μ_σ = numpyro.sample(\"μ_σ\", dist.HalfNormal(np.sqrt(np.pi/2) * hyperparameters['σ_param']))\n",
    "\n",
    "    n_pairs = len(np.unique(pool_code))\n",
    "    with numpyro.plate(\"levels\", n_pairs):\n",
    "        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n",
    "        β_1 = numpyro.sample(\"β_1\", dist.Normal(μ_β_1, σ_β_1))\n",
    "        β_2 = numpyro.sample(\"β_2\", dist.Normal(μ_β_2, σ_β_2))\n",
    "        σ = numpyro.sample(\"σ\", dist.HalfNormal(np.sqrt(np.pi/2) * μ_σ))\n",
    "\n",
    "    μ_ijt = α[pool_code] + β_1[pool_code] * logX_ijt[:,0] + β_2[pool_code] * logX_ijt[:,1] + β_3 * logX_ijt[:,2]\n",
    "    σ_ij = σ[pool_code]\n",
    "    \n",
    "    with numpyro.plate(\"data\", len(pool_code)):\n",
    "        numpyro.sample(\"logM_ijt\", dist.TruncatedNormal(μ_ijt, σ_ij, low=0), obs=logM_ijt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_intercept_partial(pool_code, logX_ijt, hyperparameters, logM_ijt=None):\n",
    "    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(10))\n",
    "\n",
    "    μ_α = numpyro.sample(\"μ_α\", dist.Normal(hyperparameters['Β_param'][0], np.sqrt(np.diag(hyperparameters['cov_Β'])[0])))\n",
    "    β_1 = numpyro.sample(\"β_1\", dist.Normal(hyperparameters['Β_param'][1], np.sqrt(np.diag(hyperparameters['cov_Β'])[1])))\n",
    "    β_2 = numpyro.sample(\"β_2\", dist.Normal(hyperparameters['Β_param'][2], np.sqrt(np.diag(hyperparameters['cov_Β'])[2])))\n",
    "    β_3 = numpyro.sample(\"β_3\", dist.Normal(hyperparameters['Β_param'][3], np.sqrt(np.diag(hyperparameters['cov_Β'])[3])))\n",
    "    β_4 = numpyro.sample(\"β_4\", dist.Normal(hyperparameters['Β_param'][4], np.sqrt(np.diag(hyperparameters['cov_Β'])[4])))\n",
    "    μ_σ = numpyro.sample(\"μ_σ\", dist.HalfNormal(np.sqrt(np.pi/2) * hyperparameters['σ_param']))\n",
    "\n",
    "    n_pairs = len(np.unique(pool_code))\n",
    "    with numpyro.plate(\"levels\", n_pairs):\n",
    "        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n",
    "        σ = numpyro.sample(\"σ\", dist.HalfNormal(np.sqrt(np.pi/2) * μ_σ))\n",
    "\n",
    "    μ_ijt = α[pool_code] + β_1 * logX_ijt[:,0] + β_2 * logX_ijt[:,1] + β_3 * logX_ijt[:,2] + β_4 * logX_ijt[:,3]\n",
    "    σ_ij = σ[pool_code]\n",
    "\n",
    "    with numpyro.plate(\"data\", len(pool_code)):\n",
    "        numpyro.sample(\"logM_ijt\", dist.TruncatedNormal(μ_ijt, σ_ij, low=0), obs=logM_ijt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_fully_partial(pool_code, logX_ijt, hyperparameters, logM_ijt=None):\n",
    "    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(10))\n",
    "    σ_β_1 = numpyro.sample(\"σ_β_1\", dist.HalfNormal(10))\n",
    "    σ_β_2 = numpyro.sample(\"σ_β_2\", dist.HalfNormal(10))\n",
    "    σ_β_3 = numpyro.sample(\"σ_β_3\", dist.HalfNormal(10))\n",
    "    σ_β_4 = numpyro.sample(\"σ_β_4\", dist.HalfNormal(10))\n",
    "\n",
    "    μ_α = numpyro.sample(\"μ_α\", dist.Normal(hyperparameters['Β_param'][0], np.sqrt(np.diag(hyperparameters['cov_Β'])[0])))\n",
    "    μ_β_1 = numpyro.sample(\"μ_β_1\", dist.Normal(hyperparameters['Β_param'][1], np.sqrt(np.diag(hyperparameters['cov_Β'])[1])))\n",
    "    μ_β_2 = numpyro.sample(\"μ_β_2\", dist.Normal(hyperparameters['Β_param'][2], np.sqrt(np.diag(hyperparameters['cov_Β'])[2])))\n",
    "    μ_β_3 = numpyro.sample(\"μ_β_3\", dist.Normal(hyperparameters['Β_param'][3], np.sqrt(np.diag(hyperparameters['cov_Β'])[3])))\n",
    "    μ_β_4 = numpyro.sample(\"μ_β_4\", dist.Normal(hyperparameters['Β_param'][4], np.sqrt(np.diag(hyperparameters['cov_Β'])[4])))\n",
    "    μ_σ = numpyro.sample(\"μ_σ\", dist.HalfNormal(np.sqrt(np.pi/2) * hyperparameters['σ_param']))\n",
    "\n",
    "    n_pairs = len(np.unique(pool_code))\n",
    "    with numpyro.plate(\"levels\", n_pairs):\n",
    "        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n",
    "        β_1 = numpyro.sample(\"β_1\", dist.Normal(μ_β_1, σ_β_1))\n",
    "        β_2 = numpyro.sample(\"β_2\", dist.Normal(μ_β_2, σ_β_2))\n",
    "        β_3 = numpyro.sample(\"β_3\", dist.Normal(μ_β_3, σ_β_3))\n",
    "        β_4 = numpyro.sample(\"β_4\", dist.Normal(μ_β_4, σ_β_4))\n",
    "        σ = numpyro.sample(\"σ\", dist.HalfNormal(np.sqrt(np.pi/2) * μ_σ))\n",
    "\n",
    "    μ_ijt = α[pool_code] + β_1[pool_code] * logX_ijt[:,0] + β_2[pool_code] * logX_ijt[:,1] + β_3[pool_code] * logX_ijt[:,2] + β_4[pool_code] * logX_ijt[:,3]\n",
    "    σ_ij = σ[pool_code]\n",
    "    \n",
    "    with numpyro.plate(\"data\", len(pool_code)):\n",
    "        numpyro.sample(\"logM_ijt\", dist.TruncatedNormal(μ_ijt, σ_ij, low=0), obs=logM_ijt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, prng_seed=prng_seed, print_progress=False, path_count=path_count, vi=True):\n",
    "\n",
    "    mae_model, r_squared_model, cpc_model, cpcd_model = np.empty(path_count), np.empty(path_count), np.empty(path_count), np.empty(path_count)\n",
    "    \n",
    "    observations = np.random.normal(np.repeat(df_train.query(\"path_ind == 0\").M_ij_mean, num_resamples)  ,  \n",
    "                np.repeat(df_train.query(\"path_ind == 0\").M_ij_sd, num_resamples)).astype('int')\n",
    "\n",
    "    tmp = pd.DataFrame(np.repeat(df_train.query(\"path_ind == 0\").values, num_resamples, axis=0), columns=df_train.columns)\n",
    "    tmp.loc[:,'M_ij'] = observations\n",
    "\n",
    "    df_train_filtered = tmp.query(\"M_ij > 0\")\n",
    "    if model in (hg_intercept_partial, hg_fully_partial):\n",
    "        X_train = df_train_filtered.set_index('State_pair')[['P_i','P_j','D_ij']]\n",
    "        pair_le = LabelEncoder().fit(X_train.index)\n",
    "        pair_code = pair_le.transform(X_train.index)\n",
    "    elif model in (hr_intercept_partial, hr_fully_partial):\n",
    "        X_train = df_train_filtered.set_index('State_pair')[['P_i','P_j','SP_ij']]\n",
    "        X_train['P_i + SP_ij'] = X_train.P_i + X_train.SP_ij\n",
    "        X_train['P_i + P_j + SP_ij'] = X_train.P_i + X_train.P_j + X_train.SP_ij\n",
    "        pair_le = LabelEncoder().fit(X_train.index)\n",
    "        pair_code = pair_le.transform(X_train.index)\n",
    "        X_train.drop('SP_ij', axis=1, inplace=True)\n",
    "        \n",
    "    X_train = np.log(X_train.astype('float').values)\n",
    "    y_train = np.log(df_train_filtered.M_ij.astype('float').values)\n",
    "\n",
    "    Β_param = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n",
    "    α_param = y_train.mean() - Β_param @ X_train.mean(axis=0)\n",
    "    ε = y_train - α_param - Β_param @ X_train.T\n",
    "    σ_param = np.sqrt(ε @ ε / ( X_train.shape[0] - X_train.shape[1] - 1 ))\n",
    "    cov_Β = σ_param * np.linalg.inv(sm.add_constant(X_train).T @ sm.add_constant(X_train))\n",
    "    hyperparameters = {'Β_param': np.concatenate([[α_param],Β_param]),\n",
    "                    'σ_param': σ_param,\n",
    "                    'cov_Β': cov_Β}\n",
    "    \n",
    "    if model in (hg_intercept_partial, hr_intercept_partial):\n",
    "        reparam_config = {\"α\": LocScaleReparam(0)}\n",
    "    elif model == hg_fully_partial:\n",
    "        reparam_config = {\"α\": LocScaleReparam(0), \"β_1\": LocScaleReparam(0), \"β_2\": LocScaleReparam(0)}\n",
    "    elif model == hr_fully_partial:\n",
    "        reparam_config = {\"α\": LocScaleReparam(0), \"β_1\": LocScaleReparam(0), \"β_2\": LocScaleReparam(0), \"β_3\": LocScaleReparam(0), \"β_4\": LocScaleReparam(0)}\n",
    "\n",
    "    reparam_model = reparam(model, config=reparam_config)\n",
    "    \n",
    "    if vi:\n",
    "        guide = AutoDiagonalNormal(reparam_model, init_loc_fn=numpyro.infer.init_to_feasible)\n",
    "        svi = SVI(reparam_model, guide, Adam(learning_rate), Trace_ELBO())\n",
    "        svi_result = svi.run(prng_seed, vi_iters, pair_code, X_train, hyperparameters, y_train, progress_bar=print_progress)\n",
    "        neutra = NeuTraReparam(guide, svi_result.params)\n",
    "        reparam_model = neutra.reparam(reparam_model)\n",
    "\n",
    "    nuts_kernel = NUTS(reparam_model, init_strategy=numpyro.infer.init_to_feasible, target_accept_prob=target_accept_prob, max_tree_depth=max_tree_depth)\n",
    "\n",
    "    mcmc = MCMC(nuts_kernel, num_warmup=num_warmup, num_samples=num_samples, progress_bar=print_progress)\n",
    "    \n",
    "    mcmc.warmup(prng_seed, pair_code, X_train, hyperparameters, y_train, collect_warmup=True, extra_fields=[\"potential_energy\"])\n",
    "    poten_model = mcmc.get_extra_fields()[\"potential_energy\"]\n",
    "    divergences_model = mcmc.get_extra_fields()[\"diverging\"]\n",
    "    mcmc.run(prng_seed, pair_code, X_train, hyperparameters, y_train)\n",
    "    \n",
    "    if vi:\n",
    "        posteriors_model = neutra.transform_sample(mcmc.get_samples()['auto_shared_latent'])\n",
    "    else:\n",
    "        posteriors_model = mcmc.get_samples()\n",
    "    \n",
    "    for path in df.path_ind.unique()[:path_count]:\n",
    "\n",
    "        df_test_filtered = df_test.query(\"path_ind == @path & M_ij != 0 & State_pair in {}\".format(list(df_train_filtered.State_pair.unique())))\n",
    "\n",
    "        if model in (hg_intercept_partial, hg_fully_partial):\n",
    "            X_test = df_test_filtered.set_index('State_pair')[['P_i','P_j','D_ij']]\n",
    "            pair_code = pair_le.transform(X_test.index)\n",
    "        elif model in (hr_intercept_partial, hr_fully_partial):\n",
    "            X_test = df_test_filtered.set_index('State_pair')[['P_i','P_j','SP_ij']]\n",
    "            X_test['P_i + SP_ij'] = X_test.P_i + X_test.SP_ij\n",
    "            X_test['P_i + P_j + SP_ij'] = X_test.P_i + X_test.P_j + X_test.SP_ij\n",
    "            pair_code = pair_le.transform(X_test.index)\n",
    "            X_test.drop('SP_ij', axis=1, inplace=True)\n",
    "\n",
    "        X_test = np.log(X_test.astype('float').values)\n",
    "        y_test = df_test_filtered.M_ij\n",
    "\n",
    "        predictive = Predictive(reparam_model, posteriors_model, return_sites=[\"logM_ijt\"])\n",
    "\n",
    "        samples_predictive = predictive(prng_seed, pair_code, X_test, hyperparameters)\n",
    "\n",
    "        pred = np.exp( samples_predictive[\"logM_ijt\"].mean(axis=0) )\n",
    "\n",
    "        mae_model[path] = mae(y_test, pred )\n",
    "        r_squared_model[path] = r_squared(y_test, pred)\n",
    "        cpc_model[path] = cpc(y_test, pred)\n",
    "        cpcd_model[path] = cpcd(y_test, pred, df_test_filtered.D_ij)\n",
    "\n",
    "        print(\"Path {}/{} delivers MAE {:0.3f}\".format(path+1,path_count, mae_model[path]))\n",
    "    \n",
    "    model_results = {'mae_model': mae_model,\n",
    "                     'r_squared_model': r_squared_model,\n",
    "                     'cpc_model': cpc_model,\n",
    "                     'cpcd_model': cpcd_model,\n",
    "                     'poten_model': poten_model,\n",
    "                     'posteriors_model': posteriors_model,\n",
    "                     'divergences': divergences_model\n",
    "    }\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model_results):\n",
    "    print(\"----------------------------------------------\")\n",
    "    for metric in list(model_results.keys())[:4]:\n",
    "        print(\"{}: {:0.3f}, +/- {:0.3f}\".format(metric,\n",
    "                                    model_results[metric].mean(),\n",
    "                                    norm.ppf(.975) * model_results[metric].std(ddof=1) / np.sqrt(path_count)\n",
    "            )\n",
    "        )\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\"Percent of warm-up transitions that are divergent: {:0.1f}%\".format(100*np.array(model_results['divergences']).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(model_results):\n",
    "    with open('../results/{}.pkl'.format(f'{model_results=}'.split('=')[0]), 'wb') as f:\n",
    "        pickle.dump(model_results, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "mae_model: 0.000, +/- 0.000\n",
      "r_squared_model: 0.000, +/- 0.000\n",
      "cpc_model: 0.000, +/- 0.000\n",
      "cpcd_model: 0.000, +/- 0.000\n",
      "----------------------------------------------\n",
      "Percent of warm-up transitions that are divergent: 1.6%\n"
     ]
    }
   ],
   "source": [
    "hg_intercept_partial_results_upsampled = run_experiment(hg_intercept_partial, print_progress=False, path_count=5, vi=True)\n",
    "\n",
    "print_results(hg_intercept_partial_results_upsampled)\n",
    "# save_results(hg_intercept_partial_results_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying intercept & coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "mae_model: 0.000, +/- 0.000\n",
      "r_squared_model: 0.000, +/- 0.000\n",
      "cpc_model: 0.000, +/- 0.000\n",
      "cpcd_model: 0.000, +/- 0.000\n",
      "----------------------------------------------\n",
      "Percent of warm-up transitions that are divergent: 2.4%\n"
     ]
    }
   ],
   "source": [
    "hg_fully_partial_results_upsampled = run_experiment(hg_fully_partial, path_count=5, vi=True)\n",
    "\n",
    "print_results(hg_fully_partial_results_upsampled)\n",
    "# save_results(hg_fully_partial_results_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 1/5 delivers MAE 1068.069\n",
      "Path 2/5 delivers MAE 1079.170\n",
      "Path 3/5 delivers MAE 1043.206\n",
      "Path 4/5 delivers MAE 1086.266\n",
      "Path 5/5 delivers MAE 1074.553\n",
      "----------------------------------------------\n",
      "mae_model: 1070.253, +/- 14.474\n",
      "r_squared_model: 0.830, +/- 0.006\n",
      "cpc_model: 0.827, +/- 0.002\n",
      "cpcd_model: 0.960, +/- 0.001\n",
      "----------------------------------------------\n",
      "Percent of warm-up transitions that are divergent: 2.4%\n"
     ]
    }
   ],
   "source": [
    "hr_intercept_partial_results_upsampled = run_experiment(hr_intercept_partial, path_count=5, vi=True)\n",
    "\n",
    "print_results(hr_intercept_partial_results_upsampled)\n",
    "# save_results(hr_intercept_partial_results_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying intercept & coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 1/5 delivers MAE 1066.853\n",
      "Path 2/5 delivers MAE 1080.202\n",
      "Path 3/5 delivers MAE 1043.461\n",
      "Path 4/5 delivers MAE 1084.733\n",
      "Path 5/5 delivers MAE 1073.525\n",
      "----------------------------------------------\n",
      "mae_model: 1069.755, +/- 14.184\n",
      "r_squared_model: 0.831, +/- 0.006\n",
      "cpc_model: 0.827, +/- 0.002\n",
      "cpcd_model: 0.961, +/- 0.001\n",
      "----------------------------------------------\n",
      "Percent of warm-up transitions that are divergent: 2.4%\n"
     ]
    }
   ],
   "source": [
    "hr_fully_partial_results_upsampled = run_experiment(hr_fully_partial, path_count=5, vi=False)\n",
    "\n",
    "print_results(hr_fully_partial_results_upsampled)\n",
    "save_results(hr_fully_partial_results_upsampled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
